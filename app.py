import streamlit as st
import google.generativeai as genai

from langchain_community.document_loaders import PyPDFLoader
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter

# ================= Page config =================
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…ØµØ±ÙŠ", page_icon="âš–ï¸")


# ================= Session state =================
if "vectorstore" not in st.session_state:
    st.session_state.vectorstore = None

if "chat_history" not in st.session_state:
    st.session_state.chat_history = []


# ================= File upload =================
uploaded_file = st.file_uploader("ğŸ“„ Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF Ù„Ù„Ù‚Ø§Ù†ÙˆÙ†", type=["pdf"])

if uploaded_file:
    with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„Ù..."):
        # âœ… SAVE PDF TEMPORARILY (FIX)
        with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as tmp_file:
            tmp_file.write(uploaded_file.read())
            tmp_path = tmp_file.name

        # âœ… LOAD PDF CORRECTLY
        loader = PyPDFLoader(tmp_path)
        pages = loader.load()

        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=1000,
            chunk_overlap=200
        )
        chunks = text_splitter.split_documents(pages)

        embeddings = HuggingFaceEmbeddings(
            model_name="sentence-transformers/all-MiniLM-L6-v2"
        )

        st.session_state.vectorstore = FAISS.from_documents(chunks, embeddings)

    st.success("âœ”ï¸ ØªÙ… ØªØ­Ù…ÙŠÙ„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ù…Ù„Ù PDF Ø¨Ù†Ø¬Ø§Ø­!")


# ================= AI RESPONSE =================
def get_ai_response(user_question):
    try:
        GOOGLE_API_KEY = "AIzaSyAcpxzbnfE-uCmKZFl77sbWR9WnTAdTeno"
        genai.configure(api_key=GOOGLE_API_KEY)

        model = genai.GenerativeModel("gemini-2.5-flash")

        context = ""
        found_info = False

        if st.session_state.vectorstore:
            results = st.session_state.vectorstore.similarity_search(user_question, k=3)
            for doc in results:
                if doc.page_content.strip():
                    found_info = True
                    context += doc.page_content + "\n"

        if found_info:
            instructions = f"""
Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…ØªØ®ØµØµ ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…ØµØ±ÙŠ.

Ø§Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªØ§Ù„ÙŠØ© Ù…Ù† Ù…Ù„Ù PDF:
{context}

Ù‚ÙˆØ§Ø¹Ø¯:
- Ø£Ø¬Ø¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
- Ø§Ø°ÙƒØ± Ø£Ø±Ù‚Ø§Ù… Ø§Ù„Ù…ÙˆØ§Ø¯ Ø¥Ù† Ø£Ù…ÙƒÙ†
- Ù‡Ø°Ù‡ Ù„ÙŠØ³Øª Ø§Ø³ØªØ´Ø§Ø±Ø© Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø±Ø³Ù…ÙŠØ©

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_question}
"""
        else:
            instructions = f"""
Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¥Ø¬Ø§Ø¨Ø© Ø¯Ø§Ø®Ù„ Ù…Ù„Ù PDF.

- Ø£Ø¬Ø¨ Ù…Ù† Ù…Ø¹Ø±ÙØªÙƒ Ø§Ù„Ø¹Ø§Ù…Ø©
- Ù†Ø¨Ù‡ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø£Ù† Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ù„ÙŠØ³Øª Ù…Ù† Ø§Ù„Ù…Ù„Ù

Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:
{user_question}
"""

        response = model.generate_content(instructions)
        return response.text

    except Exception as e:
        return f"Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"


# ================= UI =================
st.title("âš–ï¸ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…ØµØ±ÙŠ")
st.info("ğŸ’¡ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙŠÙ‚Ø¯Ù… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø¹Ø§Ù…Ø© ÙˆÙ„ÙŠØ³ Ø¨Ø¯ÙŠÙ„Ø§Ù‹ Ø¹Ù† Ù…Ø­Ø§Ù…Ù")

with st.sidebar:
    st.markdown("### ğŸ“‹ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª")
    st.markdown("""
    ÙŠØ³Ø§Ø¹Ø¯Ùƒ ÙÙŠ:
    - ÙÙ‡Ù… Ø§Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ù…ØµØ±ÙŠØ©
    - Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ©
    - Ø§Ù„Ø£Ø³Ø¦Ù„Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
    """)
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.chat_history = []
        st.rerun()


# ================= Topics =================
selected_topic = None
if len(st.session_state.chat_history) == 0:
    selected_topic = st.pills(
        "Ù…ÙˆØ§Ø¶ÙŠØ¹ Ø´Ø§Ø¦Ø¹Ø©:",
        [
            "Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¹Ù…Ù„",
            "Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø£Ø­ÙˆØ§Ù„ Ø§Ù„Ø´Ø®ØµÙŠØ©",
            "Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…Ø¯Ù†ÙŠ",
            "Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¬Ù†Ø§Ø¦ÙŠ",
            "Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ø¥ÙŠØ¬Ø§Ø±Ø§Øª",
            "Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„ØªØ¬Ø§Ø±Ø©"
        ],
        selection_mode="single"
    )


# ================= Chat =================
for msg in st.session_state.chat_history:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

user_question = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù‡Ù†Ø§...")

if selected_topic:
    user_question = f"Ø£Ø®Ø¨Ø±Ù†ÙŠ Ø¹Ù† {selected_topic} ÙÙŠ Ø§Ù„Ù‚Ø§Ù†ÙˆÙ† Ø§Ù„Ù…ØµØ±ÙŠ"

if user_question:
    st.session_state.chat_history.append(
        {"role": "user", "content": user_question}
    )

    with st.chat_message("user"):
        st.markdown(user_question)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø«..."):
            answer = get_ai_response(user_question)
            st.markdown(answer)

    st.session_state.chat_history.append(
        {"role": "assistant", "content": answer}
    )

    st.rerun()
